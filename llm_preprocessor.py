#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM ì „ì²˜ë¦¬ â†’ {"tokens":[{"gloss":"...","seconds":...},...]} plan.json ìƒì„±
(ì˜µì…˜) generatorë¥¼ --plan_json ìœ¼ë¡œ ì´ì–´ì„œ ìµœì¢… JSONLê¹Œì§€ ì¶œë ¥

ìš”êµ¬:
  - pip install openai
  - í™˜ê²½ë³€ìˆ˜ OPENROUTER_API_KEY ì„¤ì • (OpenRouter API í‚¤)
  - templates_root(ë“¤) í•˜ìœ„ì— <ê¸€ë¡œìŠ¤> ë””ë ‰í„°ë¦¬ì™€ *.npz ê°€ ì¡´ì¬í•´ì•¼ í•¨
  - text2sign_retrieval_full.py ì— --plan_json ì˜µì…˜ì´ êµ¬í˜„ë˜ì–´ ìˆê±°ë‚˜
    (ë¯¸êµ¬í˜„ì´ë©´ ì´ ìŠ¤í¬ë¦½íŠ¸ë¡œ planë§Œ ë§Œë“¤ê³ , generatorëŠ” ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì…ë ¥ ì‚¬ìš©)

ì‚¬ìš© ì˜ˆ:
  # 1) ê³„íšë§Œ ë§Œë“¤ê¸°
  python llm_preprocessor.py --templates_root "data/templates_crowd_v2" \
      --text "ì˜¤ëŠ˜ ê³µì—° ì™€ì¤˜ì„œ ê°ì‚¬í•©ë‹ˆë‹¤" --out_plan "out/plan.json"

  # 2) ê³„íš ë§Œë“¤ê³  ê³§ë°”ë¡œ generator ì‹¤í–‰(ê¶Œì¥)
  python llm_preprocessor.py --templates_root "data/templates_crowd_v2" \
      --text "ì˜¤ëŠ˜ ê³µì—° ì™€ì¤˜ì„œ ê°ì‚¬í•©ë‹ˆë‹¤" --out_plan "out/plan.json" \
      --generate --generator_path "text2sign_retrieval_full.py" \
      --out_jsonl "out/sign_sentence.jsonl" --fps 30 --fade_frames 6 --gap_frames 3 --pick median
"""

import os, re, json, time, argparse, subprocess
from pathlib import Path
from typing import List, Dict, Any, Set

# ----------------------------
# AllowedGlosses ìˆ˜ì§‘
# ----------------------------
def build_allowed_glosses(templates_root: str) -> List[str]:
    """
    templates_root: "rootA;rootB" ì²˜ëŸ¼ ; ë¡œ ì—¬ëŸ¬ ê²½ë¡œ ì „ë‹¬ ê°€ëŠ¥
    gloss í›„ë³´ëŠ” ê° ë£¨íŠ¸ í•˜ìœ„ì˜ 'ê¸€ë¡œìŠ¤ëª…' ë””ë ‰í„°ë¦¬(ê·¸ ì•ˆì— *.npz ì¡´ì¬)ì—ì„œ ìˆ˜ì§‘
    """
    roots = [p.strip() for p in templates_root.split(";") if p.strip()]
    gls: Set[str] = set()
    for rt in roots:
        rt_path = Path(rt)
        if not rt_path.exists():
            continue
        # ê¸€ë¡œìŠ¤ í´ë”: ê·¸ ì•ˆì— npzê°€ í•˜ë‚˜ ì´ìƒ ìˆëŠ” ë””ë ‰í† ë¦¬
        for d in rt_path.rglob("*"):
            if d.is_dir():
                try:
                    if any(pp.suffix == ".npz" for pp in d.glob("*.npz")):
                        gls.add(d.name)
                except Exception:
                    pass
    return sorted(gls)

# ----------------------------
# OpenRouter LLM í˜¸ì¶œ (OpenAI SDK í˜¸í™˜)
# ----------------------------
def call_llm_make_plan(text: str, allowed: List[str], model: str = "openrouter/auto", temperature: float = 0.1, max_tokens: int = 512) -> Dict[str, Any]:
    from openai import OpenAI
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        raise RuntimeError("í™˜ê²½ë³€ìˆ˜ OPENROUTER_API_KEY ê°€ ì—†ìŠµë‹ˆë‹¤. OpenRouter API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key)

    allowed_preview = ", ".join(allowed[:200])  # í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ë³´í˜¸
    system = f"""
ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì¥ì„ ìˆ˜ì–´ ê¸€ë¡œìŠ¤ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ê¸°ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì•„ë˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…, ì½”ë“œë¸”ë¡, ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€.

ê·œì¹™:
- ê¸€ë¡œìŠ¤ëŠ” AllowedGlosses ì§‘í•© ì•ˆì—ì„œë§Œ ì„ íƒí•©ë‹ˆë‹¤.
- ë¬¸ì¥ë¶€í˜¸(, . ! ? ë“±)ëŠ” <PAUSE>ë¡œ ë³€í™˜í•´ë„ ë©ë‹ˆë‹¤.
- secondsëŠ” 0.3~2.5 ë²”ìœ„ ì†Œìˆ˜ë¡œ ì¶”ì •(ê¸°ë³¸ 1.0). ì¤‘ìš” í† í°ì€ 1.2~1.6ê¹Œì§€ ëŠ˜ë¦´ ìˆ˜ ìˆìŒ.
- AllowedGlossesì— ì •í™•íˆ ì—†ìœ¼ë©´ ê°€ì¥ ì˜ë¯¸ê°€ ê°€ê¹Œìš´ ê¸€ë¡œìŠ¤ 1ê°œë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
- ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì™¸ í•„ë“œëŠ” ì ˆëŒ€ ë„£ì§€ ë§ ê²ƒ.

AllowedGlosses(ì¼ë¶€): {allowed_preview}
ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:
{{"tokens":[{{"gloss":"...", "seconds":1.0}}, ...]}}
""".strip()

    for attempt in range(3):
        resp = client.chat.completions.create(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": text}
            ],
        )
        raw = resp.choices[0].message.content.strip()
        try:
            plan = json.loads(raw)
            if not isinstance(plan, dict) or "tokens" not in plan:
                raise ValueError("LLM ì‘ë‹µì— tokens í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return plan
        except Exception:
            if attempt == 2:
                raise RuntimeError(f"LLM JSON íŒŒì‹± ì‹¤íŒ¨: {raw[:300]}")
            time.sleep(0.4)
    raise RuntimeError("LLM í˜¸ì¶œ ì‹¤íŒ¨")

# ----------------------------
# ê³„íš ê²€ì¦/ì •ê·œí™”
# ----------------------------
_PUNCT_RE = re.compile(r"[,\.\!\?\:\;\(\)\[\]\{\}â€¦~\-_/]")

def sanitize_plan(plan: Dict[str, Any], allowed: List[str]) -> Dict[str, Any]:
    allowed_set = set(allowed)
    tokens = []
    for t in plan.get("tokens", []):
        g = str(t.get("gloss", "")).strip()
        s = float(t.get("seconds", 1.0))
        # ë¬¸ì¥ë¶€í˜¸ â†’ <PAUSE>
        if _PUNCT_RE.fullmatch(g):
            g = "<PAUSE>"
        # ê¸€ë¡œìŠ¤ ë²”ìœ„ ë³´ì •
        if g != "<PAUSE>" and g not in allowed_set:
            # ê°€ì¥ ê°€ê¹Œìš´ í›„ë³´ ì°¾ê¸°(ê°„ë‹¨ edit distance)
            g = _nearest_gloss(g, allowed) or g
        # seconds ë²”ìœ„ ë³´ì •
        s = max(0.3, min(2.5, s))
        tokens.append({"gloss": g, "seconds": s})
    if not tokens:
        tokens = [{"gloss": "<PAUSE>", "seconds": 0.5}]
    return {"tokens": tokens}

def _edit_distance(a: str, b: str) -> int:
    la, lb = len(a), len(b)
    dp = list(range(lb+1))
    for i in range(1, la+1):
        prev, dp[0] = dp[0], i
        for j in range(1, lb+1):
            cur = dp[j]
            cost = 0 if a[i-1] == b[j-1] else 1
            dp[j] = min(dp[j]+1, dp[j-1]+1, prev+cost)
            prev = cur
    return dp[-1]

def _nearest_gloss(name: str, allowed: List[str], max_ed: int = 2) -> str:
    if name in allowed:
        return name
    best, best_ed = None, 10**9
    for g in allowed:
        ed = _edit_distance(name, g)
        if ed < best_ed:
            best_ed, best = ed, g
    return best if best_ed <= max_ed else name

# ----------------------------
# íŒŒì¼ ì…ì¶œë ¥ / generator ì—°ë™
# ----------------------------
def write_plan(plan: Dict[str, Any], out_path: str):
    Path(out_path).parent.mkdir(parents=True, exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(plan, f, ensure_ascii=False)
    print(f"âœ… plan.json ì €ì¥: {out_path}")

def run_generator_with_plan(generator_path: str, templates_root: str, plan_json: str,
                            out_jsonl: str, fps: int, fade_frames: int, gap_frames: int, pick: str):
    cmd = [
        "python", generator_path,
        "--templates_root", templates_root,
        "--plan_json", plan_json,
        "--out", out_jsonl,
        "--fps", str(fps),
        "--fade_frames", str(fade_frames),
        "--gap_frames", str(gap_frames),
        "--pick", pick
    ]
    print("â–¶ ì‹¤í–‰:", " ".join(cmd))
    subprocess.check_call(cmd)
    print(f"ğŸ¬ generator ì™„ë£Œ â†’ {out_jsonl}")

# ----------------------------
# CLI
# ----------------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--templates_root", required=True, help="í…œí”Œë¦¿ ë£¨íŠ¸(ì—¬ëŸ¬ ê°œëŠ” ; ë¡œ ì—°ê²°)")
    ap.add_argument("--text", required=True, help="ì…ë ¥ ë¬¸ì¥ (STT ê²°ê³¼)")
    ap.add_argument("--out_plan", default="out/plan.json", help="LLM ê³„íš JSON ì €ì¥ ê²½ë¡œ")
    ap.add_argument("--model", default="openrouter/auto", help="OpenRouter ëª¨ë¸ ID")
    ap.add_argument("--temperature", type=float, default=0.1)
    ap.add_argument("--max_tokens", type=int, default=512)

    # generator ì—°ë™(ì˜µì…˜)
    ap.add_argument("--generate", action="store_true", help="ê³„íš ìƒì„± í›„ generator ì‹¤í–‰")
    ap.add_argument("--generator_path", default="text2sign_retrieval_full.py")
    ap.add_argument("--out_jsonl", default="out/sign_sentence.jsonl")
    ap.add_argument("--fps", type=int, default=30)
    ap.add_argument("--fade_frames", type=int, default=6)
    ap.add_argument("--gap_frames", type=int, default=3)
    ap.add_argument("--pick", choices=["median","random"], default="median")

    args = ap.parse_args()

    # 1) í—ˆìš© ê¸€ë¡œìŠ¤ ìˆ˜ì§‘
    allowed = build_allowed_glosses(args.templates_root)
    if not allowed:
        raise RuntimeError(f"í…œí”Œë¦¿ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {args.templates_root}")

    # 2) LLM í˜¸ì¶œ â†’ plan ì´ˆì•ˆ
    raw_plan = call_llm_make_plan(args.text, allowed, model=args.model, temperature=args.temperature, max_tokens=args.max_tokens)

    # 3) ì„œë²„ë‹¨ ì •ê·œí™”
    plan = sanitize_plan(raw_plan, allowed)

    # 4) ì €ì¥
    write_plan(plan, args.out_plan)

    # 5) (ì˜µì…˜) generator ì‹¤í–‰
    if args.generate:
        run_generator_with_plan(
            generator_path=args.generator_path,
            templates_root=args.templates_root,
            plan_json=args.out_plan,
            out_jsonl=args.out_jsonl,
            fps=args.fps, fade_frames=args.fade_frames, gap_frames=args.gap_frames, pick=args.pick
        )

if __name__ == "__main__":
    main()
